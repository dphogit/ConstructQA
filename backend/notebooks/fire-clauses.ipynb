{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fire Clauses\n",
    "\n",
    "This notebook demonstrates the QA pipeline using the fire clauses from `fire-clauses.json`.\n",
    "It shows how to:\n",
    "1. Create embeddings using `sentence-transformers` and save them to a numpy file\n",
    "2. Perform a manual test query (rather than using Qdrant) to simulate the semantic search process\n",
    "3. Performs extraction of answers from the closest matches using a BERT model from `transformers`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:53:17.888925Z",
     "start_time": "2023-06-19T09:53:17.877696400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Uni\\\\SE700 - Research Project\\\\ConstructQA\\\\backend\\\\notebooks\\\\..\\\\data'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), '..', 'data')\n",
    "DATA_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:08.451713400Z",
     "start_time": "2023-06-19T08:36:08.382719800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                              content  \\\nclause                                                                                                  \nC1—Objectives of clauses C2 to C6 (protection f...  The objectives of clauses C2 to C6 are to: (a)...   \nC2.1                                                Fixed appliances using controlled combustion a...   \nC2.2                                                The maximum surface temperature of combustible...   \nC2.3                                                Fixed appliances using controlled combustion a...   \nC3.1                                                Buildings must be designed and constructed so ...   \nC3.2                                                Buildings with a building height greater than ...   \nC3.3                                                Buildings must be designed and constructed so ...   \nC3.5                                                Buildings must be designed and constructed so ...   \nC3.6                                                Buildings must be designed and constructed so ...   \nC3.7                                                External walls of buildings that are located c...   \n\n                                                                                   limitOnApplication  \nclause                                                                                                 \nC1—Objectives of clauses C2 to C6 (protection f...                                                     \nC2.1                                                                                                   \nC2.2                                                                                                   \nC2.3                                                                                                   \nC3.1                                                                                                   \nC3.2                                                Clause C3.2 does not apply to importance level...  \nC3.3                                                                                                   \nC3.5                                                                                                   \nC3.6                                                                                                   \nC3.7                                                                                                   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>limitOnApplication</th>\n    </tr>\n    <tr>\n      <th>clause</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C1—Objectives of clauses C2 to C6 (protection from fire)</th>\n      <td>The objectives of clauses C2 to C6 are to: (a)...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C2.1</th>\n      <td>Fixed appliances using controlled combustion a...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C2.2</th>\n      <td>The maximum surface temperature of combustible...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C2.3</th>\n      <td>Fixed appliances using controlled combustion a...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C3.1</th>\n      <td>Buildings must be designed and constructed so ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C3.2</th>\n      <td>Buildings with a building height greater than ...</td>\n      <td>Clause C3.2 does not apply to importance level...</td>\n    </tr>\n    <tr>\n      <th>C3.3</th>\n      <td>Buildings must be designed and constructed so ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C3.5</th>\n      <td>Buildings must be designed and constructed so ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C3.6</th>\n      <td>Buildings must be designed and constructed so ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>C3.7</th>\n      <td>External walls of buildings that are located c...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the fire clauses into a dataframe\n",
    "path = os.path.join(DATA_DIR, 'fire-clauses.json')\n",
    "df = pd.read_json(path)\n",
    "\n",
    "# Because the clause is unique, we can use it as the index\n",
    "# Handle limitOnApplication NaNs by replacing with empty string\n",
    "df.set_index('clause', inplace=True)\n",
    "df['limitOnApplication'].fillna('', inplace=True)\n",
    "\n",
    "# First 10 clauses\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:08.469719800Z",
     "start_time": "2023-06-19T08:36:08.412723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load in the sentence transformer model - have a look and the comparisons here:\n",
    "# https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models/\n",
    "# multi-qa-MiniLM-L6-cos-v1 is trained for QA and is smaller with very minor loss in performance\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:10.185256300Z",
     "start_time": "2023-06-19T08:36:08.461718400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93609159d7e54a78bc6e02e85ab7dcf9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(12, 384)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the clause contents to create sentence vector embeddings (combine `content` and `limitOnApplication`)\n",
    "\n",
    "sentences = (df['content'] + ' ' + df['limitOnApplication']).tolist()\n",
    "vectors = model.encode(sentences, show_progress_bar=True)\n",
    "\n",
    "# Expect a mxn matrix where m is the number of clauses and n is the embedding dimension of the model\n",
    "vectors.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:10.981258400Z",
     "start_time": "2023-06-19T08:36:10.186258700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Save the vectors to a numpy file for the script to load and insert into Qdrant\n",
    "\n",
    "save_path = os.path.join(DATA_DIR, 'fire-clauses.npy')\n",
    "np.save(save_path, vectors, allow_pickle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:11.018255100Z",
     "start_time": "2023-06-19T08:36:10.977261100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Test Query and Semantic Search\n",
    "\n",
    "Make sure that our vectors have been converted expectedly where we manually search for a clause and find the closest match (we don't use Qdrant here yet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sentence_transformers import util"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:11.037277400Z",
     "start_time": "2023-06-19T08:36:10.993271200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How high must the smoke be above the floor when firefighters put out a fire with water?\n",
      "\n",
      "Expected context: Firecells located within 15 m of a relevant boundary that are not protected by an automatic fire sprinkler system, and that contain a fire load greater than 20 TJ or that have a floor area greater than 5,000 m2  must be designed and constructed so that at the time that firefighters first apply water to the fire, the maximum radiation flux at 1.5 m above the floor is no greater than 4.5 kW/m2 and the smoke layer is not less than 2 m above the floor.\n"
     ]
    }
   ],
   "source": [
    "# Target clause C3.8\n",
    "question = 'How high must the smoke be above the floor when firefighters put out a fire with water?'\n",
    "context = df[df.index == 'C3.8']['content'].values[0]\n",
    "\n",
    "print(f'Question: {question}')\n",
    "print()\n",
    "print(f'Expected context: {context}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:11.041263300Z",
     "start_time": "2023-06-19T08:36:11.018255100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(384,)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the question\n",
    "question_vector = model.encode(question)\n",
    "question_vector.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:11.140255400Z",
     "start_time": "2023-06-19T08:36:11.023261300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  content\nclause                                                   \nC3.8    Firecells located within 15 m of a relevant bo...\nC3.5    Buildings must be designed and constructed so ...\nC3.1    Buildings must be designed and constructed so ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n    </tr>\n    <tr>\n      <th>clause</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>C3.8</th>\n      <td>Firecells located within 15 m of a relevant bo...</td>\n    </tr>\n    <tr>\n      <th>C3.5</th>\n      <td>Buildings must be designed and constructed so ...</td>\n    </tr>\n    <tr>\n      <th>C3.1</th>\n      <td>Buildings must be designed and constructed so ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for the top 3 closest matches - we use cosine similarity and gain all the scores in asc order.\n",
    "# With the sorted scores we get the last 3 (top 3) and then flip for descending order.\n",
    "# We then obtain from the data frame the clauses that match the top 3 scores\n",
    "\n",
    "scores = util.cos_sim(np.array([question_vector]), vectors)[0]\n",
    "top_score_ids = np.argsort(scores)[-3:].flip(0)\n",
    "top_scored_rows = df.iloc[top_score_ids][['content']]\n",
    "top_scored_rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:06:58.830208900Z",
     "start_time": "2023-06-19T09:06:58.809208200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see clause C3.8 was the top match.In the actual application, these embeddings need to be persisted in an actual vector database which we use Qdrant for. Qdrant has a client library to perform semantic search and have a nicer developer experience."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Answer Extraction with BERT\n",
    "\n",
    "From our top matches, we will attempt to extract the answer from the context using a BERT model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = 'deepset/tinyroberta-squad2'\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:58:01.821732900Z",
     "start_time": "2023-06-19T08:57:59.945252Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method 1: Using the `pipeline` from `transformers` for automatic inference\n",
    "\n",
    "This is a more beginner-friendly approach, providing a general abstraction and allows you to use any of the pre-trained models from `transformers` to complete any inference task. We also show different ways to obtain answers from a varying number of contexts which could be used for experiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:14:58.202598Z",
     "start_time": "2023-06-19T09:14:58.185701100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.7597898244857788, 'start': 432, 'end': 435, 'answer': '2 m'}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result from top single context\n",
    "qa_pipeline(question=question, context=top_scored_rows['content'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:17:29.758774200Z",
     "start_time": "2023-06-19T09:17:29.638775500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.602828860282898, 'start': 432, 'end': 435, 'answer': '2 m'}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the top contexts and get the answer from the concatenated context\n",
    "qa_pipeline(question=question, context=''.join(top_scored_rows['content'].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:32:01.449684200Z",
     "start_time": "2023-06-19T09:32:01.268688300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.7597898244857788, 'start': 432, 'end': 435, 'answer': '2 m'},\n {'score': 0.00023280322784557939, 'start': 82, 'end': 87, 'answer': '3.5 m'},\n {'score': 1.883208866626518e-11,\n  'start': 117,\n  'end': 150,\n  'answer': 'close proximity to a fire source.'}]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual answers from each context and get/sort by their probability scores\n",
    "qa_pipeline(question=[question] * len(top_scored_rows), context=top_scored_rows['content'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:33:13.457656600Z",
     "start_time": "2023-06-19T09:33:13.144930Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method 2: Applying the model directly\n",
    "\n",
    "This approach allows for more control over the inference process. This approach allows you to perform further research and analysis on the model's (intermediate) outputs and integrations for custom workflows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Encode using the tokenizer\n",
    "inputs = tokenizer(question, top_scored_rows['content'][0], return_tensors='pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T09:59:44.935671Z",
     "start_time": "2023-06-19T09:59:44.909165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([132, 475])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no_grad() to disable gradient calculation as we are only performing inference and don't need back propagation\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the tokens of the predicted answer\n",
    "start_idx, end_idx = outputs.start_logits.argmax(), outputs.end_logits.argmax()\n",
    "predicted_answer_tokens = inputs['input_ids'][0, start_idx:end_idx + 1]\n",
    "predicted_answer_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T10:05:27.890487100Z",
     "start_time": "2023-06-19T10:05:27.778491300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'2 m'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the tokens back to words to obtain the answer (trim string)\n",
    "tokenizer.decode(predicted_answer_tokens, skip_special_tokens=True).strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T10:05:29.776343400Z",
     "start_time": "2023-06-19T10:05:29.731218300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
